#include "ASIFT_UNIBO/asiftdetector.h"
#include <QCoreApplication>
#include <iostream>
#include <opencv/cv.hpp>
//#include <opencv2/nonfree/features2d.hpp>
#include <opencv2/imgproc/imgproc.hpp>
#include <opencv2/highgui/highgui.hpp>
#include <math.h>
#include <vl/generic.h>
#include <vl/mathop.h>
#include <vl/sift.h>
#include <vl/host.h>
#include <sstream>

#define _USE_MATH_DEFINES
#define ABS(x)    (((x) > 0) ? (x) : (-(x)))

using namespace cv;
using namespace std;

struct sortByResponse
{
    inline bool operator() (const std::pair<KeyPoint,std::vector<int>>& a, const std::pair<KeyPoint,std::vector<int>>& b)
    {
        return (a.first.size < b.first.size);
    }
};

// make sure vectorA and vectorB are of the same size, before calling function
template <typename T, typename R, typename Compare>
void sortVecPair(std::vector<T>& vecA, std::vector<R>& vecB, Compare cmp)
{

    std::vector<pair<T,R>> vecC;
    vecC.reserve(vecA.size());
    for(int i=0; i<vecA.size(); i++)
     {
        vecC.push_back(std::make_pair(vecA[i],vecB[i]));
     }

    std::sort(vecC.begin(), vecC.end(), cmp);

    vecA.clear();
    vecB.clear();
    vecA.reserve(vecC.size());
    vecB.reserve(vecC.size());
    for(int i=0; i<vecC.size(); i++)
     {
        vecA.push_back(vecC[i].first);
        vecB.push_back(vecC[i].second);
     }
}

ASiftDetector::ASiftDetector(int peakTh, float edgeTh,int nOctaves,int tilts): mPeakTh(peakTh),mEdgeTh(edgeTh),
    mOctaves(nOctaves),mTilts(tilts){
}

ASiftDetector::~ASiftDetector(){
   // Deallocate the memory that was previously reserved
   //  for this string.
   cout<<"__________"<<endl;
}


vector<vector<int> > ASiftDetector::vedaldiDetect(const IplImage* Image, vector< KeyPoint >& keypoints){//, vector<vector<int> > descriptorsOut){
    keypoints.clear();

    vector<vector<int> > descriptorsOut;

    int nlevels=2,o_min=0;

    vl_sift_pix *ImageData=new vl_sift_pix[Image->height*Image->width];
    unsigned char *Pixel;
    for (int i=0;i<Image->height;i++)
    {
        for (int j=0;j<Image->width;j++)
        {
            Pixel=(unsigned char*)(Image->imageData+i*Image->width+j);
            ImageData[i*Image->width+j]=*(Pixel);
        }
    }
    VlSiftFilt *SiftFilt=NULL;
    SiftFilt=vl_sift_new(Image->width,Image->height,mOctaves,nlevels,o_min);

    vl_sift_set_edge_thresh(SiftFilt,mEdgeTh);
    vl_sift_set_peak_thresh(SiftFilt,mPeakTh);

    int KeyPoint=0;
    int idx=0;

    if (vl_sift_process_first_octave(SiftFilt,ImageData)!=VL_ERR_EOF)
    {
        while (TRUE)
        {
            vl_sift_detect(SiftFilt);
            KeyPoint+=SiftFilt->nkeys;
            VlSiftKeypoint const *pKeyPoint=SiftFilt->keys;

            for (int i=0;i<SiftFilt->nkeys;i++)
            {
                VlSiftKeypoint TemptKeyPoint=*pKeyPoint;
                pKeyPoint++;
                idx++;

                double angles[4];

                int angleCount=1;
                try{
                    angleCount=vl_sift_calc_keypoint_orientations(SiftFilt,angles,&TemptKeyPoint);
                }
                catch (int e){
                    angles [0] = 0;
                    angles [1] = VL_PI / 2 ;
                    angles [2] = VL_PI - (VL_PI / 2) ;
                    angles [3] = VL_PI;
                }

                for (int j=0;j<angleCount;j++)
                {
                    double TemptAngle=angles[j];
                    cv::KeyPoint kp;//(TemptKeyPoint.x,TemptKeyPoint.y, TemptKeyPoint.s, TemptKeyPoint.sigma ,0, 0,-1);
                    kp.pt.x=TemptKeyPoint.x;
                    kp.pt.y=TemptKeyPoint.y;
                    //The descriptor size is determined by multiplying the keypoint scale by this factor. It is set by vl_sift_set_magnif.
                    //See: http://www.vlfeat.org/api/sift.html
                    kp.octave = vl_sift_get_octave_index(SiftFilt);
                    kp.size = ABS(TemptKeyPoint.s) * vl_sift_get_magnif(SiftFilt) * (kp.octave+1);
                    //According to the docs
                    kp.angle = - TemptKeyPoint.sigma;


                    keypoints.push_back(kp);

                    vl_sift_pix dscr[128];
                    vl_sift_calc_keypoint_descriptor(SiftFilt,dscr,&TemptKeyPoint,TemptAngle);

                    vector<int> row(128);
                    for(int t=0;t<128;t++){
                        float x =  512.0F * dscr[t];
                        x = (x < 255.0F) ? x : 255.0F;
                        row[t]=int(x);
                    }
                    descriptorsOut.push_back(row);
                }
            }

            if (vl_sift_process_next_octave(SiftFilt)==VL_ERR_EOF)
            {
                break;
            }

            KeyPoint=NULL;
        }
    }
    //delete[] SiftFilt;
    vl_sift_delete(SiftFilt);
    delete []ImageData;
    ImageData=NULL;
    SiftFilt = NULL;
    Pixel = NULL;

    return descriptorsOut;
}

void compensate_affine_coor1(float *x0, float *y0, int w1, int h1, float t1, float t2, float Rtheta)
{
  float x_ori, y_ori;
  float x_tmp, y_tmp;

  float x1 = *x0;
  float y1 = *y0;


  Rtheta = Rtheta*VL_PI/180;

  if ( Rtheta <= VL_PI/2 )
  {
    x_ori = 0;
    y_ori = w1 * sin(Rtheta) / t1;
  }
  else
  {
    x_ori = -w1 * cos(Rtheta) / t2;
    y_ori = ( w1 * sin(Rtheta) + h1 * sin(Rtheta-VL_PI/2) ) / t1;
  }

  float sin_Rtheta = sin(Rtheta);
  float cos_Rtheta = cos(Rtheta);


  /* project the coordinates of im1 to original image before tilt-rotation transform */
  /* Get the coordinates with respect to the 'origin' of the original image before transform */
  x1 = x1 - x_ori;
  y1 = y1 - y_ori;
  /* Invert tilt */
  x1 = x1 * t2;
  y1 = y1 * t1;
  /* Invert rotation (Note that the y direction (vertical) is inverse to the usual concention. Hence Rtheta instead of -Rtheta to inverse the rotation.) */
  x_tmp = cos_Rtheta*x1 - sin_Rtheta*y1;
  y_tmp = sin_Rtheta*x1 + cos_Rtheta*y1;
  x1 = x_tmp;
  y1 = y_tmp;

  *x0 = x1;
  *y0 = y1;
}



bool pointIsAcceptable( KeyPoint vl_keypoint, int width, int height){
    bool retVal= false;
    double x0, y0, vx1, vy1, vx2, vy2, vx3, vy3 ,vx4, vy4, d1, d2, d3, d4, scale1, BorderTh;

    x0 = vl_keypoint.pt.x;
    y0 = vl_keypoint.pt.y;
    scale1= vl_keypoint.size;

    if(x0<=0 || y0<=0 || x0>=width || y0>=height){
        return false;
    }

    vx1=0;
    vy1=0;

    vx2=0;
    vy2=height;

    vx3=width;
    vy3=0;

    vx4=width;
    vy4=height;

    d1 = sqrt(pow((x0-vx1),2)+pow((y0-vy1),2));
    d2 = sqrt(pow((x0-vx2),2)+pow((y0-vy2),2));
    d3 = sqrt(pow((x0-vx3),2)+pow((y0-vy3),2));
    d4 = sqrt(pow((x0-vx4),2)+pow((y0-vy4),2));

    float BorderFact=width/100*sqrt(2.);
    //if (scale1 < 1){ scale1 = 1;}
    BorderTh = BorderFact*scale1;

    if (d1<BorderTh || d2<BorderTh || d3<BorderTh || d4<BorderTh){
      retVal = false;
    } else {
      retVal = true;
    }
    return retVal;
}


void ASiftDetector::computeAsift(const Mat &img, std::vector<KeyPoint> & keypoints, vector<vector<int> > & descriptors,int maxTiepoints)
{

  keypoints.clear();
  double rsf = 1.0;

  std::vector<KeyPoint> kps0;
  kps0.clear();
  vector<vector<int>> desc0;
  desc0.clear();

//  IplImage* iplImg = new IplImage(img);
//  //IplImage* iplImg = cvCreateImage(Size(iplImg->width, iplImg->height),IPL_DEPTH_8U,1);
//  iplImg = new IplImage(img);
//  //IplImage* grayImage0 = cvCloneImage(iplImg); //new IplImage(img);
//  //IplImage *grayImage0 = cvCreateImage(cvSize(iplImg->width, iplImg->height),IPL_DEPTH_8U,1);
//  //grayImage0 = cvCloneImage(iplImg);
//  IplImage *grayImage = cvCreateImage(cvSize( iplImg->width, iplImg->height ), IPL_DEPTH_8U , 1 );//IPL_DEPTH_

//  if (iplImg->nChannels>1){
//      cvCvtColor(iplImg,grayImage,CV_BGR2GRAY);
//  } else {
//      grayImage = cvCloneImage(iplImg);
//  }

//  Mat rImg = cvarrToMat(grayImage);
//  resize(rImg,rImg,Size(0,0),rsf,rsf,INTER_LINEAR);

  int i = 0;
  //The number of tilt has been reduced to 3
  for(int tl = 1; tl <= mTilts; tl++)//for(int tl = 1; tl < 6; tl++)//for(int tl = 1; tl < 6; tl++)//for(int tl = 1; tl < 6; tl++)
  {
    double t = pow(2, 0.5*tl);
    for(int phi = 0; phi < 180; phi += 72.0/t)
    {
      i++;
      std::vector<KeyPoint> kps;
      kps.clear();
      vector<vector<int>> desc;
      desc.clear();
      Mat timg, mask, Ai;

      //affineSkew2(t, phi,rImg,timg,mask,Ai);
      img.copyTo(timg);
      affineSkew(t,phi,timg,mask,Ai);
//      cout << "PROCESS N. " << i << endl;
//      cout << "TILT:" << t << endl;
//      cout << "ANGLE:" << phi << endl;

      IplImage* tIplImg = new IplImage(timg);
      desc = vedaldiDetect(tIplImg,kps);

      for(unsigned int i = 0; i < kps.size(); i++)
      {
        Point3f kpt(kps[i].pt.x, kps[i].pt.y, 1);
        Mat kpt_t = Ai*Mat(kpt);

        kps[i].pt.x = kpt_t.at<float>(0,0)/rsf;
        kps[i].pt.y = kpt_t.at<float>(1,0)/rsf;
        if(phi == 0 || pointIsAcceptable(kps[i],img.cols,img.rows)){
            keypoints.push_back(kps[i]);
            descriptors.push_back(desc[i]);
        }
        kpt_t.release();
      }

      delete[] tIplImg;
      tIplImg = NULL;
      timg.release();
      mask.release();
      Ai.release();
    }
  }

  //tiepoints Filter

    if (maxTiepoints!=-1 && maxTiepoints<keypoints.size()) {
        //Sort tiepoints by strength
        sortVecPair(keypoints, descriptors, sortByResponse());
        std::vector<KeyPoint>  *keypointsAux = new std::vector<KeyPoint>(keypoints.end() - maxTiepoints, keypoints.end());
        vector<vector<int> >  *descriptorsAux= new vector<vector<int> >(descriptors.end() - maxTiepoints, descriptors.end());
        keypoints.clear();
        descriptors.clear();
        keypoints.reserve( keypointsAux->size()); // preallocate memory
        descriptors.reserve( descriptorsAux->size()); // preallocate memory

        keypoints.insert( keypoints.end(), keypointsAux->begin(), keypointsAux->end() );
        descriptors.insert( descriptors.end(), descriptorsAux->begin(), descriptorsAux->end() );
    }


//  cvReleaseImage(&grayImage);
//  rImg.release();
}

void ASiftDetector::affineSkew(double tilt, double phi, Mat& img, Mat& mask, Mat& Ai)
{
  int h = img.rows;
  int w = img.cols;

  mask = Mat(h, w, CV_8UC1, Scalar(255));

  Mat A = Mat::eye(2,3, CV_32F);

  if(phi != 0.0)
  {
    phi *= CV_PI/180.;
    double s = sin(phi);
    double c = cos(phi);

    A = (Mat_<float>(2,2) << c, -s, s, c);

    Mat corners = (Mat_<float>(4,2) << 0, 0, w, 0, w, h, 0, h);
    Mat tcorners = corners*A.t();
    Mat tcorners_x, tcorners_y;
    tcorners.col(0).copyTo(tcorners_x);
    tcorners.col(1).copyTo(tcorners_y);
    std::vector<Mat> channels;
    channels.push_back(tcorners_x);
    channels.push_back(tcorners_y);
    merge(channels, tcorners);

    Rect rect = boundingRect(tcorners);
    A =  (Mat_<float>(2,3) << c, -s, -rect.x, s, c, -rect.y);

    warpAffine(img, img, A, Size(rect.width, rect.height), INTER_LINEAR, BORDER_REPLICATE);
  }
  if(tilt != 1.0)
  {
    double s = 0.8*sqrt(tilt*tilt-1);
    GaussianBlur(img, img, Size(0,0), s, 0.01);
    resize(img, img, Size(0,0), 1.0/tilt, 1.0, INTER_NEAREST);
    A.row(0) = A.row(0)/tilt;
  }
  if(tilt != 1.0 || phi != 0.0)
  {
    h = img.rows;
    w = img.cols;
    warpAffine(mask, mask, A, Size(w, h), INTER_NEAREST);
  }
  invertAffineTransform(A, Ai);
}

